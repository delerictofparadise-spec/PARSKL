import requests
from bs4 import BeautifulSoup
import json
import time
from urllib.parse import urljoin, urlencode
from datetime import datetime


class KleinanzeigenParser:
    def __init__(self):
        self.base_url = "https://www.kleinanzeigen.de"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        self.categories = {
            '1': 'Auto, Rad & Boot',
            '2': 'Immobilien',
            '3': 'Familie, Kind & Baby',
            '4': 'Haus & Garten',
            '5': 'Elektronik',
            '6': 'Freizeit, Hobby & Nachbarschaft',
            '7': 'Mode & Beauty',
            '8': 'Musik, Film & Buch',
            '9': 'Dienstleistungen',
            '10': 'Unterricht & Kurse',
            '11': 'Jobs',
            '12': 'Tiere'
        }

    def show_menu(self):
        print("\n" + "=" * 60)
        print("KLEINANZEIGEN PARSER - –†–ê–°–®–ò–†–ï–ù–ù–´–ï –§–ò–õ–¨–¢–†–´")
        print("=" * 60)

        print("\n--- –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ ---")
        for key, value in self.categories.items():
            print(f"{key}. {value}")

        category = input("\n–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏—é (Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞): ").strip()

        query = input("\n–í–≤–µ–¥–∏—Ç–µ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å: ").strip()

        location = input("–í–≤–µ–¥–∏—Ç–µ –≥–æ—Ä–æ–¥/—Ä–µ–≥–∏–æ–Ω (Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞): ").strip()

        print("\n" + "=" * 60)
        print("üí∞ –§–ò–õ–¨–¢–†–´ –ü–û –¶–ï–ù–ï")
        print("=" * 60)
        price_from = input("–¶–µ–Ω–∞ –æ—Ç (Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞): ").strip()
        price_to = input("–¶–µ–Ω–∞ –¥–æ (Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞): ").strip()

        print("\n" + "=" * 60)
        print("üì¶ –§–ò–õ–¨–¢–†–´ –ü–û –ü–†–û–î–ê–í–¶–£")
        print("=" * 60)
        seller_ads_from = input("–ú–∏–Ω. –∫–æ–ª-–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π —É –ø—Ä–æ–¥–∞–≤—Ü–∞ (Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞): ").strip()
        seller_ads_to = input("–ú–∞–∫—Å. –∫–æ–ª-–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π —É –ø—Ä–æ–¥–∞–≤—Ü–∞ (Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞): ").strip()

        print("\n--- –î–∞—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –ø—Ä–æ–¥–∞–≤—Ü–∞ ---")
        seller_reg_from = input("–ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω –ø–æ—Å–ª–µ (–î–î-–ú–ú-–ì–ì–ì–ì, Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞): ").strip()
        seller_reg_to = input("–ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω –¥–æ (–î–î-–ú–ú-–ì–ì–ì–ì, Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞): ").strip()

        print("\n" + "=" * 60)
        print("üëÄ –§–ò–õ–¨–¢–†–´ –ü–û –û–ë–™–Ø–í–õ–ï–ù–ò–Æ")
        print("=" * 60)
        views_min = input("–ú–∏–Ω. –∫–æ–ª-–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ (Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞): ").strip()

        print("\n--- –î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ ---")
        pub_date_from = input("–û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ –ø–æ—Å–ª–µ (–î–î-–ú–ú-–ì–ì–ì–ì, Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞): ").strip()
        pub_date_to = input("–û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ –¥–æ (–î–î-–ú–ú-–ì–ì–ì–ì, Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞): ").strip()

        print("\n--- –î–æ—Å—Ç–∞–≤–∫–∞ ---")
        print("1. –¢–æ–ª—å–∫–æ —Å –¥–æ—Å—Ç–∞–≤–∫–æ–π")
        print("2. –¢–æ–ª—å–∫–æ –±–µ–∑ –¥–æ—Å—Ç–∞–≤–∫–∏")
        print("3. –ù–µ –∏–º–µ–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è")
        shipping_filter = input("–í—ã–±–µ—Ä–∏—Ç–µ –≤–∞—Ä–∏–∞–Ω—Ç (Enter - –Ω–µ –∏–º–µ–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è): ").strip()

        print("\n--- –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ–ø–ª–∞—Ç–∞ ---")
        print("1. –¢–æ–ª—å–∫–æ —Å –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –æ–ø–ª–∞—Ç–æ–π")
        print("2. –¢–æ–ª—å–∫–æ –±–µ–∑ –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –æ–ø–ª–∞—Ç—ã")
        print("3. –ù–µ –∏–º–µ–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è")
        safe_payment = input("–í—ã–±–µ—Ä–∏—Ç–µ –≤–∞—Ä–∏–∞–Ω—Ç (Enter - –Ω–µ –∏–º–µ–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è): ").strip()

        print("\n--- –°–æ—Å—Ç–æ—è–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ ---")
        print("1. –ù–æ–≤–æ–µ")
        print("2. –ë/—É")
        print("3. –ù–µ –∏–º–µ–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è")
        condition = input("–í—ã–±–µ—Ä–∏—Ç–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ (Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞): ").strip()

        print("\n--- –¢–∏–ø –æ–±—ä—è–≤–ª–µ–Ω–∏—è ---")
        print("1. –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ")
        print("2. –ü–æ–∏—Å–∫")
        print("3. –í—Å–µ")
        ad_type = input("–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø (Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞): ").strip()

        print("\n--- –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ ---")
        print("1. –ü–æ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏")
        print("2. –ü–æ –Ω–æ–≤–∏–∑–Ω–µ")
        print("3. –ü–æ —Ü–µ–Ω–µ (–≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏–µ)")
        print("4. –ü–æ —Ü–µ–Ω–µ (—É–±—ã–≤–∞–Ω–∏–µ)")
        sort_by = input("–í—ã–±–µ—Ä–∏—Ç–µ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫—É (Enter - –ø–æ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏): ").strip()

        max_pages = input("\n–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 3): ").strip()
        max_pages = int(max_pages) if max_pages.isdigit() else 3

        filters = {
            'category': category if category else None,
            'query': query if query else None,
            'location': location if location else None,
            'price_from': price_from if price_from else None,
            'price_to': price_to if price_to else None,
            'seller_ads_from': int(seller_ads_from) if seller_ads_from.isdigit() else None,
            'seller_ads_to': int(seller_ads_to) if seller_ads_to.isdigit() else None,
            'seller_reg_from': seller_reg_from if seller_reg_from else None,
            'seller_reg_to': seller_reg_to if seller_reg_to else None,
            'views_min': int(views_min) if views_min.isdigit() else None,
            'pub_date_from': pub_date_from if pub_date_from else None,
            'pub_date_to': pub_date_to if pub_date_to else None,
            'shipping_filter': shipping_filter if shipping_filter else None,
            'safe_payment': safe_payment if safe_payment else None,
            'condition': condition if condition else None,
            'ad_type': ad_type if ad_type else None,
            'sort_by': sort_by if sort_by else '1',
            'max_pages': max_pages
        }

        return filters

    def show_active_filters(self, filters):
        print("\n" + "=" * 60)
        print("‚ÑπÔ∏è  –ê–ö–¢–ò–í–ù–´–ï –§–ò–õ–¨–¢–†–´:")
        print("=" * 60)

        active = []

        if filters.get('price_from') or filters.get('price_to'):
            pf = filters.get('price_from', '0')
            pt = filters.get('price_to', '‚àû')
            active.append(f"‚û§ üí∞ –¶–µ–Ω–∞: {pf}-{pt}")

        if filters.get('seller_ads_from') or filters.get('seller_ads_to'):
            sf = filters.get('seller_ads_from', '0')
            st = filters.get('seller_ads_to', '‚àû')
            active.append(f"‚û§ üì¶ –ö–æ–ª-–≤–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π –ø—Ä–æ–¥–∞–≤—Ü–∞: {sf}-{st}")

        if filters.get('views_min'):
            active.append(f"‚û§ üëÄ –ú–∏–Ω. –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤: {filters['views_min']}")

        if filters.get('pub_date_from') or filters.get('pub_date_to'):
            pdf = filters.get('pub_date_from', '–ª—é–±–∞—è')
            pdt = filters.get('pub_date_to', '–ª—é–±–∞—è')
            active.append(f"‚û§ üìÖ –î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: {pdf} - {pdt}")

        if filters.get('seller_reg_from') or filters.get('seller_reg_to'):
            srf = filters.get('seller_reg_from', '–ª—é–±–∞—è')
            srt = filters.get('seller_reg_to', '–ª—é–±–∞—è')
            active.append(f"‚û§ üìù –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ–¥–∞–≤—Ü–∞: {srf} - {srt}")

        if filters.get('shipping_filter') == '1':
            active.append("‚û§ üöö –î–æ—Å—Ç–∞–≤–∫–∞: –¢–æ–ª—å–∫–æ —Å –¥–æ—Å—Ç–∞–≤–∫–æ–π")
        elif filters.get('shipping_filter') == '2':
            active.append("‚û§ üöö –î–æ—Å—Ç–∞–≤–∫–∞: –¢–æ–ª—å–∫–æ –±–µ–∑ –¥–æ—Å—Ç–∞–≤–∫–∏")

        if filters.get('safe_payment') == '1':
            active.append("‚û§ üíº –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ–ø–ª–∞—Ç–∞: –í–∫–ª—é—á–µ–Ω–∞")
        elif filters.get('safe_payment') == '2':
            active.append("‚û§ üíº –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ–ø–ª–∞—Ç–∞: –í—ã–∫–ª—é—á–µ–Ω–∞")

        if active:
            for f in active:
                print(f)
        else:
            print("–§–∏–ª—å—Ç—Ä—ã –Ω–µ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã")

        print("=" * 60 + "\n")

    def search(self, filters):
        results = []

        params = {}

        if filters.get('price_from'):
            params['priceFrom'] = filters['price_from']
        if filters.get('price_to'):
            params['priceTo'] = filters['price_to']

        if filters.get('condition') == '1':
            params['condition'] = 'new'
        elif filters.get('condition') == '2':
            params['condition'] = 'used'

        if filters.get('ad_type') == '1':
            params['adType'] = 'OFFER'
        elif filters.get('ad_type') == '2':
            params['adType'] = 'WANTED'

        sort_map = {
            '1': 'RELEVANCE',
            '2': 'CREATION_DATE_DESC',
            '3': 'PRICE_ASC',
            '4': 'PRICE_DESC'
        }
        params['sortBy'] = sort_map.get(filters.get('sort_by', '1'), 'RELEVANCE')

        query = filters.get('query', '')
        location = filters.get('location', '')

        if location:
            search_url = f"{self.base_url}/s-{query}/{location}/k0"
        else:
            search_url = f"{self.base_url}/s-{query}/k0"

        if params:
            search_url += '?' + urlencode(params)

        print(f"\n–ü–æ–∏—Å–∫ –ø–æ URL: {search_url}\n")

        for page in range(filters.get('max_pages', 3)):
            if page > 0:
                page_url = f"{search_url}&page={page + 1}"
            else:
                page_url = search_url

            print(f"–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page + 1}...")

            try:
                response = requests.get(page_url, headers=self.headers, timeout=10)
                response.raise_for_status()

                soup = BeautifulSoup(response.text, 'html.parser')
                ads = self.parse_listing_page(soup)

                if not ads:
                    print("–û–±—ä—è–≤–ª–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∞ —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ")
                    break

                filtered_ads = self.apply_filters(ads, filters)
                results.extend(filtered_ads)

                print(f"–ù–∞–π–¥–µ–Ω–æ {len(ads)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π, –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {len(filtered_ads)}")

                time.sleep(2)

            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page + 1}: {e}")
                break

        return results

    def apply_filters(self, ads, filters):
        filtered = []

        for ad in ads:
            if not self.check_ad_filters(ad, filters):
                continue
            filtered.append(ad)

        return filtered

    def check_ad_filters(self, ad, filters):
        # –§–∏–ª—å—Ç—Ä –ø–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞–º
        if filters.get('views_min'):
            views = ad.get('views', 0)
            if views < filters['views_min']:
                return False

        # –§–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
        if filters.get('pub_date_from') or filters.get('pub_date_to'):
            ad_date = ad.get('published_date')
            if ad_date:
                try:
                    ad_dt = datetime.strptime(ad_date, '%d-%m-%Y')

                    if filters.get('pub_date_from'):
                        from_dt = datetime.strptime(filters['pub_date_from'], '%d-%m-%Y')
                        if ad_dt < from_dt:
                            return False

                    if filters.get('pub_date_to'):
                        to_dt = datetime.strptime(filters['pub_date_to'], '%d-%m-%Y')
                        if ad_dt > to_dt:
                            return False
                except:
                    pass

        # –§–∏–ª—å—Ç—Ä –ø–æ –¥–æ—Å—Ç–∞–≤–∫–µ
        if filters.get('shipping_filter') == '1':
            if not ad.get('has_shipping'):
                return False
        elif filters.get('shipping_filter') == '2':
            if ad.get('has_shipping'):
                return False

        # –§–∏–ª—å—Ç—Ä –ø–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –æ–ø–ª–∞—Ç–µ
        if filters.get('safe_payment') == '1':
            if not ad.get('safe_payment'):
                return False
        elif filters.get('safe_payment') == '2':
            if ad.get('safe_payment'):
                return False

        # –§–∏–ª—å—Ç—Ä –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –æ–±—ä—è–≤–ª–µ–Ω–∏–π –ø—Ä–æ–¥–∞–≤—Ü–∞
        if filters.get('seller_ads_from') or filters.get('seller_ads_to'):
            seller_ads = ad.get('seller_active_ads', 0)

            if filters.get('seller_ads_from') and seller_ads < filters['seller_ads_from']:
                return False

            if filters.get('seller_ads_to') and seller_ads > filters['seller_ads_to']:
                return False

        # –§–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –ø—Ä–æ–¥–∞–≤—Ü–∞
        if filters.get('seller_reg_from') or filters.get('seller_reg_to'):
            seller_reg = ad.get('seller_registration_date')
            if seller_reg:
                try:
                    reg_dt = datetime.strptime(seller_reg, '%d-%m-%Y')

                    if filters.get('seller_reg_from'):
                        from_dt = datetime.strptime(filters['seller_reg_from'], '%d-%m-%Y')
                        if reg_dt < from_dt:
                            return False

                    if filters.get('seller_reg_to'):
                        to_dt = datetime.strptime(filters['seller_reg_to'], '%d-%m-%Y')
                        if reg_dt > to_dt:
                            return False
                except:
                    pass

        return True

    def parse_listing_page(self, soup):
        ads = []

        ad_items = soup.find_all('article', class_='aditem')

        if not ad_items:
            ad_items = soup.find_all('li', attrs={'data-adid': True})

        for item in ad_items:
            try:
                ad_data = self.parse_ad_item(item)
                if ad_data:
                    ads.append(ad_data)
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è: {e}")
                continue

        return ads

    def parse_ad_item(self, item):
        ad = {}

        ad['id'] = item.get('data-adid') or item.get('data-ad-id')

        title_elem = item.find('a', class_='ellipsis')
        if title_elem:
            ad['title'] = title_elem.text.strip()
            ad['url'] = urljoin(self.base_url, title_elem.get('href', ''))

        price_elem = item.find('p', class_='aditem-main--middle--price-shipping--price')
        if not price_elem:
            price_elem = item.find('p', string=lambda t: t and '‚Ç¨' in t)

        if price_elem:
            price_text = price_elem.text.strip()
            ad['price'] = price_text
        else:
            ad['price'] = '–ù–µ —É–∫–∞–∑–∞–Ω–∞'

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç–∞–≤–∫–∏
        shipping_text = '–ù–µ —É–∫–∞–∑–∞–Ω–∞'
        has_shipping = False

        price_shipping_container = item.find('div', class_='aditem-main--middle--price-shipping')
        if price_shipping_container:
            full_text = price_shipping_container.get_text(separator=' ', strip=True)
            if 'Versand' in full_text:
                has_shipping = True
                parts = full_text.split('Versand')
                if len(parts) > 1:
                    shipping_text = 'Versand ' + ' '.join(parts[1].split()[0:3])

        ad['shipping'] = shipping_text
        ad['has_shipping'] = has_shipping

        # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ–ø–ª–∞—Ç–∞
        safe_payment_elem = item.find(string=lambda t: t and 'K√§uferschutz' in t)
        ad['safe_payment'] = safe_payment_elem is not None

        desc_elem = item.find('p', class_='aditem-main--middle--description')
        if desc_elem:
            ad['description'] = desc_elem.text.strip()

        location_elem = item.find('div', class_='aditem-main--top--left')
        if location_elem:
            ad['location'] = location_elem.text.strip()

        # –î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
        date_elem = item.find('div', class_='aditem-main--top--right')
        if date_elem:
            date_text = date_elem.text.strip()
            ad['published_date'] = self.parse_date(date_text)

        img_elem = item.find('img')
        if img_elem:
            ad['image'] = img_elem.get('src') or img_elem.get('data-src')

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–¥–∞–≤—Ü–µ (—Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–µ—Ö–æ–¥ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –æ–±—ä—è–≤–ª–µ–Ω–∏—è)
        ad['views'] = 0
        ad['seller_active_ads'] = 0
        ad['seller_registration_date'] = None

        return ad if ad.get('title') else None

    def parse_date(self, date_text):
        try:
            if 'Heute' in date_text or 'heute' in date_text:
                return datetime.now().strftime('%d-%m-%Y')
            elif 'Gestern' in date_text or 'gestern' in date_text:
                from datetime import timedelta
                yesterday = datetime.now() - timedelta(days=1)
                return yesterday.strftime('%d-%m-%Y')
            else:
                # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–∞—Ç—É
                import re
                date_match = re.search(r'(\d{2})\.(\d{2})\.(\d{4})', date_text)
                if date_match:
                    return f"{date_match.group(1)}-{date_match.group(2)}-{date_match.group(3)}"
        except:
            pass
        return None

    def get_ad_details(self, ad_url):
        try:
            response = requests.get(ad_url, headers=self.headers, timeout=10)
            response.raise_for_status()

            soup = BeautifulSoup(response.text, 'html.parser')

            details = {
                'url': ad_url
            }

            title = soup.find('h1', id='viewad-title')
            if title:
                details['title'] = title.text.strip()

            price = soup.find('h2', id='viewad-price')
            if price:
                details['price'] = price.text.strip()

            desc = soup.find('p', id='viewad-description-text')
            if desc:
                details['description'] = desc.text.strip()

            # –ü—Ä–æ—Å–º–æ—Ç—Ä—ã
            views_elem = soup.find(string=lambda t: t and 'Aufrufe' in t)
            if views_elem:
                import re
                views_match = re.search(r'(\d+)', views_elem)
                if views_match:
                    details['views'] = int(views_match.group(1))

            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–¥–∞–≤—Ü–µ
            seller_section = soup.find('section', id='vap-seller-information')
            if seller_section:
                # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π
                active_ads_elem = seller_section.find(string=lambda t: t and 'Aktive Anzeigen' in t)
                if active_ads_elem:
                    import re
                    ads_match = re.search(r'(\d+)', active_ads_elem)
                    if ads_match:
                        details['seller_active_ads'] = int(ads_match.group(1))

                # –î–∞—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏
                reg_elem = seller_section.find(string=lambda t: t and 'Mitglied seit' in t)
                if reg_elem:
                    details['seller_registration_date'] = reg_elem.strip()

            attributes = soup.find_all('li', class_='addetailslist--detail')
            details['attributes'] = {}
            for attr in attributes:
                label = attr.find('span', class_='addetailslist--detail--label')
                value = attr.find('span', class_='addetailslist--detail--value')
                if label and value:
                    details['attributes'][label.text.strip()] = value.text.strip()

            seller = soup.find('div', id='viewad-contact')
            if seller:
                seller_name = seller.find('span', id='viewad-contact-name')
                if seller_name:
                    details['seller'] = seller_name.text.strip()

            return details

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–µ—Ç–∞–ª–µ–π –æ–±—ä—è–≤–ª–µ–Ω–∏—è: {e}")
            return None


if __name__ == "__main__":
    parser = KleinanzeigenParser()

    filters = parser.show_menu()

    parser.show_active_filters(filters)

    print("=" * 60)
    print("–ù–ê–ß–ò–ù–ê–ï–ú –ü–ê–†–°–ò–ù–ì...")
    print("=" * 60 + "\n")

    ads = parser.search(filters)

    print(f"\n{'=' * 60}")
    print(f"–†–ï–ó–£–õ–¨–¢–ê–¢–´")
    print(f"{'=' * 60}")
    print(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {len(ads)}\n")

    if ads:
        print("–ü–µ—Ä–≤—ã–µ 10 –æ–±—ä—è–≤–ª–µ–Ω–∏–π:\n")

        for i, ad in enumerate(ads[:10], 1):
            print(f"{i}. {ad.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}")
            print(f"   –¶–µ–Ω–∞: {ad.get('price', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')} | –î–æ—Å—Ç–∞–≤–∫–∞: {ad.get('shipping', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}")
            print(f"   –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ–ø–ª–∞—Ç–∞: {'‚úì' if ad.get('safe_payment') else '‚úó'}")
            print(f"   –õ–æ–∫–∞—Ü–∏—è: {ad.get('location', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}")
            print(f"   –î–∞—Ç–∞: {ad.get('published_date', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}")
            print(f"   URL: {ad.get('url', '')}")
            print()

        with open('kleinanzeigen_results.json', 'w', encoding='utf-8') as f:
            json.dump(ads, f, ensure_ascii=False, indent=2)

        print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ kleinanzeigen_results.json")
    else:
        print("–û–±—ä—è–≤–ª–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
